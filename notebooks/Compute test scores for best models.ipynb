{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import (r2_score, mean_squared_error, mean_absolute_error)\n",
    "from qptuna.three_step_opt_build_merge import (\n",
    "    buildconfig_best,\n",
    "    build_best,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7defc",
   "metadata": {},
   "source": [
    "## Algorithms, sets, endpoints, datadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "algs = [\"RF\", \"SVR\", \"xgboost\", \"PLS\"]\n",
    "sets = [\"1\", \"2\", \"3\", \"4\"]\n",
    "props = [\"Clearance\", \"logD\", \"Solubility\", \"Permeability\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c17c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08389fcc",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7453e46-51ee-4b4d-a49a-11d984bb1b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_stats(study_name):\n",
    "    \"\"\"Returns mean CV train scores\"\"\"\n",
    "    \n",
    "    file = f\"../optuna-storage/optuna_storage_{study_name}.sqlite\"\n",
    "    storage = f\"sqlite:///{os.path.abspath(file)}\"\n",
    "    \n",
    "    try:\n",
    "        loaded_study = optuna.load_study(\n",
    "            study_name=study_name, \n",
    "            storage=storage\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Could not open study {study_name} from storage {storage}: {e}\")\n",
    "        return collections.defaultdict(lambda: np.nan)  # All scores NaN.\n",
    "        \n",
    "    train_scores = loaded_study.best_trial.user_attrs[\"train_scores\"]\n",
    "\n",
    "    r2 = np.mean(train_scores[\"train_r2\"])\n",
    "    rmse = np.sqrt(-1 * np.mean(train_scores[\"train_neg_mean_squared_error\"]))\n",
    "    mae = -1 * np.mean(train_scores[\"train_neg_mean_absolute_error\"])\n",
    "    return {\"r2\": r2, \"rmse\": rmse, \"mae\": mae }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c505c-e4eb-4a06-9329-b4ca3ec7cbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(study_name):\n",
    "    \"\"\"Returns model loaded from a pickled file\"\"\"\n",
    "    \n",
    "    model_path = f\"../best-models/best-{study_name}.pkl\"\n",
    "    if not os.path.isfile(model_path):\n",
    "        print(\"Not there: \", model_path, \"\\n\")\n",
    "        return None\n",
    "\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4f2a1-c220-44f6-a337-b1b3aef71b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_stats(study_name, test_file):\n",
    "    \"\"\"Returns test scores and writes CSV with expected and predicted values\"\"\"\n",
    "    \n",
    "    model = get_model(study_name)\n",
    "    \n",
    "    if model is None:\n",
    "        return collections.defaultdict(lambda: np.nan)\n",
    "    \n",
    "    df = pd.read_csv(test_file)\n",
    "    expected = df[\"VALUE\"].to_numpy().reshape(-1, 1)  # One-column matrix.\n",
    "    predicted = model.predict_from_smiles(df[\"SMILES\"])\n",
    "\n",
    "    # R2.\n",
    "    r2 = r2_score(y_true=expected, y_pred=predicted)\n",
    "    # RMSE. sklearn 0.24 added squared=False to get RMSE, here we use np.sqrt().\n",
    "    rmse = np.sqrt(mean_squared_error(y_true=expected, y_pred=predicted))  \n",
    "    # MAE.\n",
    "    mae = mean_absolute_error(y_true=expected, y_pred=predicted)\n",
    "    \n",
    "    # Write to file y_true and y_pred for scatter plot.\n",
    "    pred_values_path = f\"../pred_values/{study_name}_testset_values.csv\"\n",
    "    dict_values = {\"SMILES\": list(df[\"SMILES\"]), \"y_true\": list(df[\"VALUE\"]), \"y_pred\": list(predicted)}\n",
    "    df_values = pd.DataFrame.from_dict(dict_values, dtype=None, columns=None)\n",
    "    df_values.to_csv(pred_values_path, index=False)\n",
    "\n",
    "    return {\"r2\": r2, \"rmse\": rmse, \"mae\": mae, \"number_of_mols\": len(df)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a07b57-902d-475a-b92c-85266c49adbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_df(datadir, prop, setid, alg):\n",
    "    \"\"\"Returns one-row DataFrame with statistics for the paper\"\"\"\n",
    "    \n",
    "    study_name = f\"MMP_{datadir}_{prop}_set{setid}_{alg}\"\n",
    "    train_file = f\"../{datadir}/{prop}_set{setid}_train.csv\"\n",
    "    train_number_of_mols = len(pd.read_csv(train_file))\n",
    "    test_file = f\"../{datadir}/{prop}_set{setid}_test.csv\"\n",
    "    \n",
    "    train = get_train_stats(study_name)\n",
    "    test = get_test_stats(study_name, test_file)\n",
    "    \n",
    "    row_data = {\n",
    "        \"endpoint\": prop,\n",
    "        \"set\": setid,\n",
    "        \"n_all\": np.nan,\n",
    "        \"n_train\": train_number_of_mols,\n",
    "        \"n_test\": test[\"number_of_mols\"],\n",
    "        \"model\": alg,\n",
    "        \"train_r2\": train[\"r2\"],\n",
    "        \"train_rmse\": train[\"rmse\"],\n",
    "        \"train_mae\": train[\"mae\"],\n",
    "        \"test_r2\": test[\"r2\"],\n",
    "        \"test_rmse\": test[\"rmse\"],\n",
    "        \"test_mae\": test[\"mae\"],\n",
    "    }\n",
    "    df_stats = pd.DataFrame(row_data, index=[0])\n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f521848",
   "metadata": {},
   "source": [
    "## Main loop to calculate all scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c37975",
   "metadata": {},
   "source": [
    "The loop comes in two versions: sequential and parallel. Choose one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b9190",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sequential version.\n",
    "df_all = pd.DataFrame()\n",
    "for prop in props:\n",
    "    for setid in sets:\n",
    "        for alg in algs:\n",
    "            print(f\"Prop: {prop}, set: {setid}, alg: {alg}\")\n",
    "            df = get_stats_df(datadir, prop, setid, alg)\n",
    "            df_all = df_all.append(df)\n",
    "\n",
    "df_all.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427d930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel version.\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "dfs = Parallel(n_jobs=7)(\n",
    "    delayed(get_stats_df)(datadir, prop, setid, alg) \n",
    "    for prop in props\n",
    "    for setid in sets\n",
    "    for alg in algs\n",
    ")\n",
    "df_all = pd.concat(dfs)\n",
    "df_all.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84590870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(\"../mmp_filled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab9e9c8",
   "metadata": {},
   "source": [
    "## Additional computation of test scores for downsampled 10% data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af643a",
   "metadata": {},
   "source": [
    "These results will be used to \"fill gaps\" in the main table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f022540",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_ds = \"downsampled-10-percent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b1481",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_ds = Parallel(n_jobs=7)(\n",
    "    delayed(get_stats_df)(datadir_ds, prop, setid, alg) \n",
    "    for prop in props\n",
    "    for setid in sets\n",
    "    for alg in algs\n",
    ")\n",
    "df_ds = pd.concat(dfs_ds)\n",
    "df_ds.reset_index()\n",
    "df_ds.to_csv(\"../mmp_filled_ds.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
